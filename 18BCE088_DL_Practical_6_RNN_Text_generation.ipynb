{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18BCE088_DL_Practical_6_RNN_Text_generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMARSN4R2TNI0DNLGJkjp5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeromepatel/DL-University-Course-Practicals/blob/master/18BCE088_DL_Practical_6_RNN_Text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FHZXXhc8mrJ"
      },
      "source": [
        "# Practical 6 - Text Generation using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfj3fBVb1WYq"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7loSIW0SdfJ"
      },
      "source": [
        "\n",
        "#importing libraries\n",
        "from matplotlib import pyplot\n",
        "# from keras.datasets.cifar10 import load_data\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, SimpleRNN\n",
        "from keras import backend as K\n",
        "# from keras.layers import Conv2D, MaxPool2D, BatchNormalization ,GlobalAveragePooling2D\n",
        "#from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "# from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from __future__ import print_function\n",
        "import spacy\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, TimeDistributed\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import GRU\n",
        "import numpy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk import word_tokenize, sent_tokenize"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkpjz8_Klfs3",
        "outputId": "720813f5-dbdb-4271-9612-e6eb28f7d84e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwnpjsOxS4Tl"
      },
      "source": [
        "#@title Alternative Text Data { display-mode: \"form\" }\n",
        "data = \"\"\" The name of my village is Pakdiyar which falls in the Gopalganj district of Bihar . \\n During the summer and winter vacations, I visit my village . \\n My grandparents live in the village . \\n They like the village more than the city where we stay . \\n My grandparentsâ€™ house is one of the biggest pakka houses in the village . \\n My grandfather is the sarpanch of the village . \\n He is admired by all the villagers for his just verdicts and actions towards the welfare of the villagers . \\n In my village, our family is highly respected . \\n My grandmother does a lot of social work for the villagers .\"\"\""
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKy1TqGdk9qF",
        "outputId": "550ecb87-4910-4b9b-fda8-92a020bf4ab1"
      },
      "source": [
        "corpus = \"\"\" Jack and Jill went up the hill . \\n To fetch a pail of water . \\n Jack fell down and broke his crown . \\n And Jill came tumbling after .\"\"\"\n",
        "tokenized_sent = corpus.split(' \\n')\n",
        "\n",
        "# tokenized_sent = sent_tokenize(data)\n",
        "# tokenized_sent = data.split(' \\n')\n",
        "tokenized_sent"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Jack and Jill went up the hill .',\n",
              " ' To fetch a pail of water .',\n",
              " ' Jack fell down and broke his crown .',\n",
              " ' And Jill came tumbling after .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpKsCV2flbWS"
      },
      "source": [
        "tokenizer=Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\]^_{/}~')\n",
        "\n",
        "tokenizer.fit_on_texts(tokenized_sent)\n",
        "# tokenizer.word_index\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49YXmSfeWa7B",
        "outputId": "c5fb2fd6-da06-43dd-cb5d-452557927dc5"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-LxtVR0l40w",
        "outputId": "a1dcd049-624d-4eb3-850c-8416649e231f"
      },
      "source": [
        "sequence = tokenizer.texts_to_sequences(tokenized_sent)\n",
        "print(f\"first sequence encoded: {sequence[0]}\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first sequence encoded: [3, 2, 4, 5, 6, 7, 8, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEv7_hPImVOG",
        "outputId": "156bd2e3-1dbc-4e5f-b63e-411a3d8f5d48"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "maxlen = 0\n",
        "for i in range(len(sequence)):\n",
        "    X.insert(i, sequence[i][:-1])\n",
        "    Y.insert(i, sequence[i])\n",
        "    maxlen = max(len(Y[i]),maxlen)\n",
        "\n",
        "X[0], Y[0], maxlen"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3, 2, 4, 5, 6, 7, 8], [3, 2, 4, 5, 6, 7, 8, 1], 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_R39U9ro9CU",
        "outputId": "13663c71-c66d-43e5-cc91-b5af32464fe9"
      },
      "source": [
        "X = pad_sequences(X,maxlen = maxlen+1, padding = 'pre')\n",
        "Y = pad_sequences(Y, maxlen = maxlen+1, padding = 'pre')\n",
        "\n",
        "X[0],Y[0]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 3, 2, 4, 5, 6, 7, 8], dtype=int32),\n",
              " array([0, 3, 2, 4, 5, 6, 7, 8, 1], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG9r87Mzpw3P",
        "outputId": "0f50fb6f-59d5-4c5c-f164-16007ff0c07c"
      },
      "source": [
        "Y = to_categorical(Y,VOCAB_SIZE)\n",
        "Y[0]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05xJ4Ltnqb91",
        "outputId": "e27412e2-24b2-4fa9-87d3-5a940a7ede1a"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=VOCAB_SIZE, output_dim=40))\n",
        "model.add(SimpleRNN(units=70, return_sequences=True))\n",
        "model.add(Dense(units=VOCAB_SIZE, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 40)          920       \n",
            "_________________________________________________________________\n",
            "simple_rnn_7 (SimpleRNN)     (None, None, 70)          7770      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, None, 23)          1633      \n",
            "=================================================================\n",
            "Total params: 10,323\n",
            "Trainable params: 10,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImBUdoZbryBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2660fc6c-4e31-4675-b8cf-6ae30737c8f1"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X,Y,epochs=200,verbose=0)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76e001c410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbcCGLAmsFko",
        "outputId": "6e2e7382-a730-4c91-d2c8-d4da084f801d"
      },
      "source": [
        "def probability_of_input_sentence(model, tokenizer, sentence):\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    encoded.insert(0, 0)\n",
        "    encoded = numpy.array(encoded)\n",
        "    encoded = encoded.reshape(1, -1)\n",
        "    prob = model.predict(encoded, verbose=0)\n",
        "    probability = 1\n",
        "    print(prob.shape)\n",
        "    for i in range(prob.shape[1]-1):\n",
        "        probability = probability * prob[0, i, encoded[0, i+1]]\n",
        "    print(f\"Probability of Sentence '{sentence}' is:\", probability)\n",
        "\n",
        "prob_of_input_sentence(model, tokenizer, \" Jill and Jack will go down\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5, 23)\n",
            "Probability of Sentence ' Jill and Jack will go down' is: 2.261855239839254e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cbgcA4G2U3x"
      },
      "source": [
        "## Text Generation (using argmax)\n",
        "Here we generate text using predicting most probable word from output probabilities, this method can give more accurate answers than sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJnyFGcCtOHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6125062-6d1b-450e-e99d-b43ccf7a8756"
      },
      "source": [
        "def generate_sentence(model, tokenizer, n_words, vocab_size):\n",
        "    sequence = [[0]]\n",
        "    for i in range(n_words):\n",
        "        probabilies = model.predict(sequence, verbose=0)\n",
        "        temp = numpy.argmax(probabilies[0][-1])\n",
        "        sequence[0] += [temp]\n",
        "    \n",
        "    sentence = tokenizer.sequences_to_texts(sequence)[0]\n",
        "    return sentence\n",
        "\n",
        "print(generate_sentence(model, tokenizer, 8, VOCAB_SIZE))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to fetch a pail of water\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o94zgvYk1Ofe"
      },
      "source": [
        "## Text Generation using Sampling Predictions\n",
        "Here we use sampled probabilites as an input to model for prediction, this method works can be less accurate to generate text but provides more variation in text generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "S7ICQ1cjz8VX",
        "outputId": "bb2c1f44-39cb-4ce9-c91c-5467cccd911d"
      },
      "source": [
        "def sample_sentences(model, tokenizer, num_words,vocab_size):\n",
        "  encoded = []\n",
        "  text = ''\n",
        "  for i in range(num_words):\n",
        "    encoded = tokenizer.texts_to_sequences([text])[0]\n",
        "    encoded.insert(0,0)\n",
        "    encoded = numpy.array(encoded)\n",
        "    encoded = numpy.reshape(encoded,newshape=(1,-1))\n",
        "\n",
        "    print(\"\\nFor:\",i,\"Encoded:\",encoded,encoded.shape)\n",
        "    if i == 0:\n",
        "      probability = model.predict(encoded, verbose = 1)\n",
        "    #   print(\"\\nFor:\",i,\"Probability:\",probability,type(probability),probability.shape)\n",
        "      yhat = 0\n",
        "      while(yhat == 0):\n",
        "        yhat = numpy.random.choice(range(vocab_size),p=probability.ravel())\n",
        "      yhat = [yhat]\n",
        "      yhat = numpy.array(yhat)\n",
        "      yhat = numpy.reshape(yhat,newshape = (1,-1))\n",
        "    else:\n",
        "      probability = model.predict(encoded,verbose=1)\n",
        "    #   print(\"\\nFor:\",i,\"Probability:\",probability,type(probability),probability.shape)\n",
        "      yhat = numpy.append(yhat,0)\n",
        "      yhat = numpy.reshape(yhat,newshape=(1,-1))\n",
        "      while yhat[0,i] == 0:\n",
        "        yhat[0,i] = numpy.random.choice(range(vocab_size),p=probability[0,i].ravel())\n",
        "    print(\"\\nFor:\",i,\"Else yhat:\",yhat,yhat.shape)\n",
        "\n",
        "    out_word = ''\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      if index == yhat[0,i]:\n",
        "        out_word = word\n",
        "        break\n",
        "\n",
        "    text = text + out_word + ' '\n",
        "  return text\n",
        "sample_sentences(model, tokenizer, 8, VOCAB_SIZE)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For: 0 Encoded: [[0]] (1, 1)\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "\n",
            "For: 0 Else yhat: [[21]] (1, 1)\n",
            "\n",
            "For: 1 Encoded: [[ 0 21]] (1, 2)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            "For: 1 Else yhat: [[21  3]] (1, 2)\n",
            "\n",
            "For: 2 Encoded: [[ 0 21  3]] (1, 3)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "For: 2 Else yhat: [[21  3 15]] (1, 3)\n",
            "\n",
            "For: 3 Encoded: [[ 0 21  3 15]] (1, 4)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "\n",
            "For: 3 Else yhat: [[21  3 15 16]] (1, 4)\n",
            "\n",
            "For: 4 Encoded: [[ 0 21  3 15 16]] (1, 5)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            "For: 4 Else yhat: [[21  3 15 16  2]] (1, 5)\n",
            "\n",
            "For: 5 Encoded: [[ 0 21  3 15 16  2]] (1, 6)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "\n",
            "For: 5 Else yhat: [[21  3 15 16  2 17]] (1, 6)\n",
            "\n",
            "For: 6 Encoded: [[ 0 21  3 15 16  2 17]] (1, 7)\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            "For: 6 Else yhat: [[21  3 15 16  2 17 18]] (1, 7)\n",
            "\n",
            "For: 7 Encoded: [[ 0 21  3 15 16  2 17 18]] (1, 8)\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "\n",
            "For: 7 Else yhat: [[21  3 15 16  2 17 18 19]] (1, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tumbling jack fell down and broke his crown '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqYqYpD3gAS"
      },
      "source": [
        "## Code by: 18BCE088 Jyot Makadiya\n"
      ]
    }
  ]
}